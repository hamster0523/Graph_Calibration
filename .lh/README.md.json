{
    "sourceFile": "README.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1766656429291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1766997517509,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,9 @@\n     - `search.py`: Defines the Web Search Agent.\r\n     - `fetch.py`: Defines the Web Read Agent for fetching page content.\r\n \r\n ### `verl_hamster/`\r\n-This appears to be a version of the **verl** (Volcano Engine Reinforcement Learning) library, which is a flexible and efficient RL training library for LLMs.\r\n+the **verl** (Volcano Engine Reinforcement Learning) library, which is a flexible and efficient RL training library for LLMs.\r\n - **Purpose:** Provides infrastructure for Reinforcement Learning from Human Feedback (RLHF) and other RL algorithms for LLMs.\r\n - **Contents:** Includes dockerfiles, documentation, examples, and the core `verl` package.\r\n \r\n ## Getting Started\r\n"
                },
                {
                    "date": 1766997687173,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,11 +42,15 @@\n     - `search.py`: Defines the Web Search Agent.\r\n     - `fetch.py`: Defines the Web Read Agent for fetching page content.\r\n \r\n ### `verl_hamster/`\r\n-the **verl** (Volcano Engine Reinforcement Learning) library, which is a flexible and efficient RL training library for LLMs.\r\n+The **verl** (Volcano Engine Reinforcement Learning) library, which is a flexible and efficient RL training library for LLMs.\r\n - **Purpose:** Provides infrastructure for Reinforcement Learning from Human Feedback (RLHF) and other RL algorithms for LLMs.\r\n - **Contents:** Includes dockerfiles, documentation, examples, and the core `verl` package.\r\n+- **Key Modules:**\r\n+    - **`Hamster_Cpt_Worker/`**: A worker service for graph-based operations. It initializes a `GraphBuilder` with a CPT model and performs inference on factor graphs.\r\n+    - **`Hamster_Generation_Manager/`**: Manages the generation process, integrating LLM generation with factor graph construction and online search. It handles trajectory initialization, prompt extraction, and interaction with VLLM and search APIs.\r\n+    - **`Hamster_Reward_Manager/`**: Computes rewards for generated trajectories using a composite reward function that includes format scores, calibration scores (KL divergence), structure scores (entropy), and step-wise rewards.\r\n \r\n ## Getting Started\r\n \r\n Please refer to the specific `README.md` files within subdirectories (e.g., `verl_hamster/README.md`) for detailed installation and usage instructions for each component.\r\n"
                }
            ],
            "date": 1766656429291,
            "name": "Commit-0",
            "content": "# Project Overview\r\n\r\nThis repository contains a collection of modules and tools related to reinforcement learning, factor graphs, and agent-based systems, likely for Large Language Model (LLM) applications.\r\n\r\nBelow is a description of the main directories and their purposes:\r\n\r\n## Directory Structure\r\n\r\n### `CPT/`\r\nContains the core implementation of the CPT (likely Conditional Probability Table or a specific model component) module.\r\n- **Key File:** `CPT.py` - Implements the CPT logic using PyTorch and Transformers.\r\n\r\n### `CPT_FactorGraph_Run/`\r\nScripts and tools for running factor graph-based executions, possibly integrating with the CPT module.\r\n- **Key Files:**\r\n    - `run_online.py`: Script for running the system in an online mode.\r\n    - `build_trajectory_to_graph.py`: Tools to convert execution trajectories into graph structures.\r\n\r\n### `eval/`\r\nEvaluation scripts and metrics for assessing model performance.\r\n- **Key Files:**\r\n    - `run.py`: Main evaluation entry point.\r\n    - `aucroc.py`: Calculates Area Under the ROC Curve.\r\n    - `run_ece_evalution.py`: Runs Expected Calibration Error evaluation.\r\n\r\n### `hamster_agent/`\r\nA comprehensive agent application framework, including backend, frontend, and core agent logic.\r\n- **Subdirectories:**\r\n    - `app/`: Core agent logic, tools, and flow definitions.\r\n    - `backend/`: API server implementation (likely FastAPI or similar).\r\n    - `frontend/`: Web interface for the agent.\r\n    - `config/`: Configuration files for different models (Anthropic, Azure, Google, etc.).\r\n\r\n### `hamster_factor_graph/`\r\nA library implementing Factor Graphs and Belief Propagation algorithms.\r\n- **Key File:** `factorgraph/factorgraph.py` - Core implementation of the factor graph data structure and inference algorithms.\r\n\r\n### `Online_Search_Server/`\r\nA standalone server or module dedicated to performing online web searches and information retrieval.\r\n- **Key Files:**\r\n    - `search_pipeline.py`: Orchestrates the search process.\r\n    - `search.py`: Defines the Web Search Agent.\r\n    - `fetch.py`: Defines the Web Read Agent for fetching page content.\r\n\r\n### `verl_hamster/`\r\nThis appears to be a version of the **verl** (Volcano Engine Reinforcement Learning) library, which is a flexible and efficient RL training library for LLMs.\r\n- **Purpose:** Provides infrastructure for Reinforcement Learning from Human Feedback (RLHF) and other RL algorithms for LLMs.\r\n- **Contents:** Includes dockerfiles, documentation, examples, and the core `verl` package.\r\n\r\n## Getting Started\r\n\r\nPlease refer to the specific `README.md` files within subdirectories (e.g., `verl_hamster/README.md`) for detailed installation and usage instructions for each component.\r\n"
        }
    ]
}