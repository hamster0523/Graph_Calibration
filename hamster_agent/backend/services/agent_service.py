"""
AgentæœåŠ¡
å¤„ç†ä¸Manus Agentçš„äº¤äº’é€»è¾‘
"""

import asyncio
import logging
import re
from datetime import datetime
from functools import wraps
from typing import Any, Dict, List, Optional

try:
    from ..models.schemas import (
        AgentActionData,
        AgentObservationData,
        AgentStatus,
        AgentStreamMessage,
        AgentThinkData,
        ChatMessage,
        ChatResponse,
        FlowConfigResponse,
        FlowConfiguration,
    )
    from .connection_manager import manager
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    try:
        from models.schemas import (
            AgentActionData,
            AgentObservationData,
            AgentStatus,
            AgentStreamMessage,
            AgentThinkData,
            ChatMessage,
            ChatResponse,
            FlowConfigResponse,
            FlowConfiguration,
        )
        from services.connection_manager import manager
    except ImportError:
        from backend.models.schemas import (
            AgentActionData,
            AgentObservationData,
            AgentStatus,
            AgentStreamMessage,
            AgentThinkData,
            ChatMessage,
            ChatResponse,
            FlowConfigResponse,
            FlowConfiguration,
        )
        from backend.services.connection_manager import manager


class StreamingLogHandler(logging.Handler):
    """è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ - å°†å…³é”®æ—¥å¿—ä¿¡æ¯è½¬æ¢ä¸ºæµå¼æ¶ˆæ¯"""

    def __init__(self, broadcast_callback):
        super().__init__()
        self.broadcast = broadcast_callback
        self.current_step = 0
        self.total_steps = 20

        # å®šä¹‰æ—¥å¿—æ¶ˆæ¯æ¨¡å¼åŒ¹é…
        self.log_patterns = {
            # Flowç›¸å…³æ¨¡å¼
            "flow_start": [
                r"Creating initial plan.*",
                r"å¼€å§‹æ‰§è¡Œ.*",
                r"Execute.*flow.*",
                r"Starting.*",
            ],
            "plan_creation": [
                r"Creating initial plan.*",
                r"Plan creation.*",
                r"è®¡åˆ’åˆ›å»º.*",
            ],
            "step_start": [
                r"æ‰§è¡Œæ­¥éª¤.*",
                r"Step.*æ‰§è¡Œ.*",
                r"Processing step.*",
                r"Current step.*",
            ],
            "step_complete": [
                r"Step.*completed.*",
                r"æ­¥éª¤.*å®Œæˆ.*",
                r"Completed step.*",
            ],
            "agent_action": [
                r"Using.*agent.*",
                r"Agent.*executing.*",
                r"Tool.*called.*",
                r"Executing.*",
            ],
            "result": [r"Result.*", r"ç»“æœ.*", r"Output.*", r"Generated.*"],
            "error": [r"Error.*", r"Failed.*", r"Exception.*", r"é”™è¯¯.*"],
        }

    def emit(self, record):
        """å¤„ç†æ—¥å¿—è®°å½•å¹¶è½¬æ¢ä¸ºæµå¼æ¶ˆæ¯"""
        try:
            log_message = record.getMessage()
            message_type, data = self._classify_log_message(log_message, record)

            if message_type and self.broadcast:
                # å¼‚æ­¥å¹¿æ’­æ¶ˆæ¯
                asyncio.create_task(self._async_broadcast(message_type, data))

        except Exception as e:
            # é¿å…åœ¨æ—¥å¿—å¤„ç†ä¸­äº§ç”Ÿæ— é™å¾ªç¯
            pass

    def _classify_log_message(self, message: str, record) -> tuple:
        """æ ¹æ®æ—¥å¿—å†…å®¹åˆ†ç±»å¹¶ç”Ÿæˆå¯¹åº”çš„æµå¼æ¶ˆæ¯"""

        # æ£€æŸ¥æ¯ç§æ¨¡å¼
        for msg_type, patterns in self.log_patterns.items():
            for pattern in patterns:
                if re.search(pattern, message, re.IGNORECASE):
                    return self._create_stream_data(msg_type, message, record)

        # é»˜è®¤å¤„ç†
        if record.levelno >= logging.WARNING:
            return self._create_stream_data("warning", message, record)
        elif record.levelno >= logging.INFO:
            return self._create_stream_data("info", message, record)

        return None, None

    def _create_stream_data(self, msg_type: str, message: str, record) -> tuple:
        """åˆ›å»ºæµå¼æ¶ˆæ¯æ•°æ®"""

        # æ ¹æ®æ¶ˆæ¯ç±»å‹ç”Ÿæˆç›¸åº”çš„æ•°æ®ç»“æ„
        if msg_type == "flow_start":
            self.current_step = 0
            return "start", {
                "description": message,
                "timestamp": datetime.now().isoformat(),
            }

        elif msg_type == "plan_creation":
            self.current_step = 1
            return "think_start", {
                "content": message,
                "reasoning": "æ­£åœ¨åˆ›å»ºæ‰§è¡Œè®¡åˆ’...",
            }

        elif msg_type == "step_start":
            self.current_step += 1
            return "step_start", {
                "step": self.current_step,
                "description": message,
                "timestamp": datetime.now().isoformat(),
            }

        elif msg_type == "step_complete":
            return "step_complete", {
                "step": self.current_step,
                "result": message[:200],
                "description": f"æ­¥éª¤ {self.current_step} å®Œæˆ",
            }

        elif msg_type == "agent_action":
            return "act", {
                "tool_name": self._extract_tool_name(message),
                "description": message,
                "timestamp": datetime.now().isoformat(),
            }

        elif msg_type == "result":
            return "observe", {
                "tool_name": "system",
                "result": message[:300],
                "success": True,
            }

        elif msg_type == "error":
            return "error", {
                "error": message,
                "description": f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                "timestamp": datetime.now().isoformat(),
            }

        else:
            return "info", {
                "content": message,
                "level": record.levelname,
                "timestamp": datetime.now().isoformat(),
            }

    def _extract_tool_name(self, message: str) -> str:
        """ä»æ—¥å¿—æ¶ˆæ¯ä¸­æå–å·¥å…·åç§°"""
        # å°è¯•åŒ¹é…å¸¸è§çš„å·¥å…·åç§°æ¨¡å¼
        tool_patterns = [
            r"tool[:\s]+(\w+)",
            r"using\s+(\w+)",
            r"executing\s+(\w+)",
            r"(\w+)\s+agent",
        ]

        for pattern in tool_patterns:
            match = re.search(pattern, message, re.IGNORECASE)
            if match:
                return match.group(1)

        return "unknown_tool"

    async def _async_broadcast(self, message_type: str, data: Dict[str, Any]):
        """å¼‚æ­¥å¹¿æ’­æµå¼æ¶ˆæ¯"""
        try:
            if self.broadcast:
                await self.broadcast(
                    message_type, data, self.current_step, self.total_steps
                )
        except Exception as e:
            # é™é»˜å¤„ç†å¹¿æ’­é”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹
            pass


class LoggingInterceptor:
    """æ—¥å¿—æ‹¦æˆªå™¨ - ä¸´æ—¶æ›¿æ¢loggerå¤„ç†å™¨"""

    def __init__(self, broadcast_callback):
        self.broadcast = broadcast_callback
        self.original_handlers = {}
        self.stream_handler = StreamingLogHandler(broadcast_callback)

    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡æ—¶å®‰è£…æ—¥å¿—æ‹¦æˆªå™¨"""
        # è·å–app.loggerç›¸å…³çš„logger
        loggers_to_intercept = [
            "app.flow",
            "app.agent",
            "app.logger",
            "app.flow.planning",
            "app.flow.data_analysis_flow",
            "app.agent.manus",
            "app.agent.base",
        ]

        for logger_name in loggers_to_intercept:
            try:
                logger = logging.getLogger(logger_name)
                # ä¿å­˜åŸå§‹å¤„ç†å™¨
                self.original_handlers[logger_name] = logger.handlers.copy()
                # æ·»åŠ æµå¼å¤„ç†å™¨
                logger.addHandler(self.stream_handler)
                # è®¾ç½®é€‚å½“çš„æ—¥å¿—çº§åˆ«
                if logger.level == logging.NOTSET:
                    logger.setLevel(logging.INFO)
            except Exception as e:
                # å¿½ç•¥ä¸å­˜åœ¨çš„logger
                pass

        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡æ—¶æ¢å¤åŸå§‹æ—¥å¿—å¤„ç†å™¨"""
        for logger_name, original_handlers in self.original_handlers.items():
            try:
                logger = logging.getLogger(logger_name)
                # ç§»é™¤æµå¼å¤„ç†å™¨
                if self.stream_handler in logger.handlers:
                    logger.removeHandler(self.stream_handler)
            except Exception as e:
                pass


class AgentService:
    """AgentæœåŠ¡ç±»"""

    def __init__(self):
        self.current_agent: Optional[Any] = None  # å®é™…çš„Manus agentå®ä¾‹
        self.current_flow: Optional[Any] = None  # å½“å‰flowå®ä¾‹
        self.status = AgentStatus(
            status="idle", current_step=0, max_steps=20, last_action="Ready")
        self.is_demo_mode = False  # å¼ºåˆ¶ç¦ç”¨æ¼”ç¤ºæ¨¡å¼
        self.llm_config = None  # LLMé…ç½®

        # Flowé…ç½®
        self.flow_config = FlowConfiguration(
            mode="single_agent", primaryAgent="manus", selectedAgents=[])

        self._load_config()

    def _load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            # å°è¯•å¯¼å…¥appçš„é…ç½®
            from app.config import config as app_config

            self.llm_config = app_config.llm.get("default")
            if self.llm_config:
                print(
                    f"âœ… Loaded LLM config: model={self.llm_config.model}, api_type={self.llm_config.api_type}"
                )
            else:
                print("âš ï¸ No default LLM config found")
        except ImportError:
            print("âš ï¸ App config not available, will use backend config service")
        except Exception as e:
            print(f"âš ï¸ Error loading app config: {e}")

        # å¦‚æœappé…ç½®ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨backendé…ç½®æœåŠ¡
        if not self.llm_config:
            try:
                # å°è¯•å¤šç§å¯¼å…¥æ–¹å¼
                try:
                    from backend.services.config_service import config_service
                except ImportError:
                    try:
                        from services.config_service import config_service
                    except ImportError:
                        from .config_service import config_service

                backend_config = config_service.get_current_config()
                llm_config = backend_config.get("llm", {})
                if llm_config:
                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„é…ç½®å¯¹è±¡
                    self.llm_config = type("LLMConfig", (), llm_config)()
                    print(
                        f"âœ… Loaded backend LLM config: model={getattr(self.llm_config, 'model', 'unknown')}"
                    )
            except Exception as e:
                print(f"âš ï¸ Error loading backend config: {e}")

    async def initialize_agent(self):
        """åˆå§‹åŒ–Agentï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        try:
            # å¼ºåˆ¶ä¸ä½¿ç”¨Demoæ¨¡å¼ - è·³è¿‡å¤æ‚çš„Manusåˆå§‹åŒ–
            print("ğŸ”§ Attempting to exit demo mode...")

            # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨
            if self.llm_config:
                print(
                    f"ğŸ”§ Using LLM configuration: {getattr(self.llm_config, 'model', 'unknown')}"
                )
                if (
                    hasattr(self.llm_config, "api_key")
                    and not getattr(self.llm_config, "api_key", "").strip()
                ):
                    print("âš ï¸ Warning: LLM API key is empty")
                else:
                    # å¦‚æœæœ‰æœ‰æ•ˆçš„APIé…ç½®ï¼Œä¸ä½¿ç”¨demoæ¨¡å¼
                    self.is_demo_mode = False
                    print("âœ… LLM configuration found, exiting demo mode")
                    return

            # å°è¯•å¯¼å…¥å¹¶åˆå§‹åŒ–çœŸå®çš„Manus agent (with timeout protection)
            from app.agent.manus import Manus

            self.current_agent = await Manus.create()
            self.is_demo_mode = False
            print("âœ… Manus agent initialized successfully")

            # æ›´æ–°æœ€å¤§æ­¥æ•°
            if hasattr(self.current_agent, "max_steps"):
                self.status.max_steps = self.current_agent.max_steps

        except ImportError as e:
            print(f"âš ï¸ Manus agent not available, checking LLM config: {e}")
            # å¦‚æœæœ‰LLMé…ç½®ï¼Œä»ç„¶å¯ä»¥ä¸ä½¿ç”¨demoæ¨¡å¼
            if (
                self.llm_config
                and hasattr(self.llm_config, "api_key")
                and getattr(self.llm_config, "api_key", "").strip()
            ):
                self.is_demo_mode = False
                print(
                    "âœ… LLM configuration available, exiting demo mode despite Manus import failure"
                )
            else:
                self.is_demo_mode = True
        except Exception as e:
            print(f"âŒ Error initializing Manus agent: {e}")
            # å¦‚æœæœ‰LLMé…ç½®ï¼Œä»ç„¶å¯ä»¥ä¸ä½¿ç”¨demoæ¨¡å¼
            if (
                self.llm_config
                and hasattr(self.llm_config, "api_key")
                and getattr(self.llm_config, "api_key", "").strip()
            ):
                self.is_demo_mode = False
                print(
                    "âœ… LLM configuration available, exiting demo mode despite Manus initialization failure"
                )
            else:
                self.is_demo_mode = True

    async def process_message(self, message: ChatMessage) -> ChatResponse:
        """å¤„ç†èŠå¤©æ¶ˆæ¯"""
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await self._update_status("processing", 1, "Processing user message")

            # å¹¿æ’­ç”¨æˆ·æ¶ˆæ¯
            await self._broadcast_user_message(message)

            if self.is_demo_mode:
                # æ¼”ç¤ºæ¨¡å¼ï¼šç”Ÿæˆæ¨¡æ‹Ÿå“åº”
                response_text = await self._generate_demo_response(message.message)
            else:
                # çœŸå®æ¨¡å¼ï¼šä½¿ç”¨Manus agent
                response_text = await self._process_with_agent(message.message)

            # å¹¿æ’­Agentå“åº”
            await self._broadcast_agent_response(response_text)

            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            await self._update_status("completed", 0, "Message processed successfully")

            return ChatResponse(
                response=response_text,
                status="success",
                timestamp=datetime.now().isoformat(),
            )

        except Exception as e:
            await self._update_status("error", 0, f"Error: {str(e)}")
            raise e

    async def _generate_demo_response(self, user_message: str) -> str:
        """ç”Ÿæˆæ¼”ç¤ºå“åº”ï¼ˆå¸¦æµå¼è¾“å‡ºï¼‰"""
        # æ¼”ç¤ºæµå¼è¾“å‡º
        await self._broadcast_stream_message(
            "start", {"description": "æ¼”ç¤ºæ¨¡å¼ Agent å¼€å§‹å¤„ç†è¯·æ±‚..."}, 0, 3
        )

        # æ¨¡æ‹Ÿæ€è€ƒé˜¶æ®µ
        await self._broadcast_stream_message(
            "think_start", {"content": "æ­£åœ¨åˆ†æç”¨æˆ·è¯·æ±‚..."}, 1, 3
        )

        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´

        await self._broadcast_stream_message(
            "think",
            {
                "content": f"ç”¨æˆ·è¯¢é—®: '{user_message}'. æˆ‘éœ€è¦ç”Ÿæˆä¸€ä¸ªåˆé€‚çš„å›åº”ã€‚",
                "reasoning": "åˆ†æå®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆå›åº”",
            },
            1,
            3,
        )

        # æ¨¡æ‹Ÿæ‰§è¡Œé˜¶æ®µ
        await self._broadcast_stream_message(
            "act",
            {"tool_name": "response_generator", "description": "æ‰§è¡Œå›åº”ç”Ÿæˆå™¨"},
            2,
            3,
        )

        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´

        # ç”Ÿæˆå›åº”é€»è¾‘
        message_lower = user_message.lower()

        if "hello" in message_lower or "hi" in message_lower:
            response = "Hello! I'm the OpenManus agent demo. How can I help you today?"
        elif "help" in message_lower:
            response = "I can assist you with various tasks including data analysis, code generation, file management, and web automation. What would you like me to help you with?"
        elif "test" in message_lower:
            response = "Test successful! The Web UI is working correctly. You can try uploading files, changing configurations, or asking me questions."
        elif "what can you do" in message_lower:
            response = "I can help you with:\nâ€¢ Data analysis and visualization\nâ€¢ Code review and generation\nâ€¢ File processing and management\nâ€¢ Web browsing and automation\nâ€¢ Search and research tasks"
        else:
            response = f"I received your message: '{user_message}'. This is a demo response. In the full version, I would process this request and provide a detailed response based on my capabilities."

        # æ¨¡æ‹Ÿè§‚å¯Ÿç»“æœ
        await self._broadcast_stream_message(
            "observe",
            {
                "tool_name": "response_generator",
                "result": f"ç”Ÿæˆå›åº”: {response[:100]}...",
                "success": True,
            },
            2,
            3,
        )

        await asyncio.sleep(0.3)  # æœ€åçš„å¤„ç†æ—¶é—´

        return response

    async def _process_with_agent(self, user_message: str) -> str:
        """ä½¿ç”¨çœŸå®Agentæˆ–Flowå¤„ç†æ¶ˆæ¯ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰"""
        try:
            print(f"ğŸ” Processing message with:")
            print(f"   Current flow: {self.current_flow is not None}")
            print(f"   Current agent: {self.current_agent is not None}")
            print(f"   Flow config mode: {self.flow_config.mode}")
            print(f"   Demo mode: {self.is_demo_mode}")

            # ä¼˜å…ˆä½¿ç”¨Flow
            if self.current_flow:
                print("âœ… Using Flow mode")
                # åˆ›å»ºæ··åˆå¼FlowåŒ…è£…å™¨ - æä¾›å¤šå±‚å®æ—¶åé¦ˆ
                stream_flow = HybridStreamingFlowWrapper(
                    self.current_flow, self._broadcast_stream_message
                )
                response = await stream_flow.run(user_message)
                return response or "Task completed successfully"
            elif self.current_agent:
                print("âœ… Using Agent mode")
                # åˆ›å»ºæµå¼AgentåŒ…è£…å™¨
                stream_agent = StreamingAgentWrapper(
                    self.current_agent, self._broadcast_stream_message
                )
                response = await stream_agent.run(user_message)
                return response or "Task completed successfully"
            elif self.current_agent is None and not self.current_flow:
                print("âš ï¸ No Flow or Agent available, checking configuration...")

                # å¦‚æœé…ç½®ä¸ºFlowæ¨¡å¼ä½†Flowä¸å­˜åœ¨ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–
                if self.flow_config.mode != "single_agent":
                    print(
                        f"ğŸ”§ Attempting to reinitialize Flow: {self.flow_config.mode}"
                    )
                    await self._initialize_flow(self.flow_config)

                    if self.current_flow:
                        print("âœ… Flow reinitialized successfully")
                        # åˆ›å»ºæ··åˆå¼FlowåŒ…è£…å™¨ - é‡æ–°åˆå§‹åŒ–åä½¿ç”¨
                        stream_flow = HybridStreamingFlowWrapper(
                            self.current_flow, self._broadcast_stream_message
                        )
                        response = await stream_flow.run(user_message)
                        return response or "Task completed successfully"
                    else:
                        return f"Failed to initialize {self.flow_config.mode} flow. Please check your configuration."
                else:
                    # Single agentæ¨¡å¼ï¼Œå°è¯•åˆå§‹åŒ–Agent
                    await self.initialize_agent()
                    if self.current_agent:
                        # åˆ›å»ºæµå¼AgentåŒ…è£…å™¨
                        stream_agent = StreamingAgentWrapper(
                            self.current_agent, self._broadcast_stream_message
                        )
                        response = await stream_agent.run(user_message)
                        return response or "Task completed successfully"

            # åªæœ‰åœ¨single_agentæ¨¡å¼ä¸”Agentä¸å¯ç”¨æ—¶æ‰å›é€€åˆ°LLM API
            if self.flow_config.mode == "single_agent":
                print("âš ï¸ Falling back to direct LLM API for single_agent mode")
                if (
                    self.llm_config
                    and hasattr(self.llm_config, "api_key")
                    and getattr(self.llm_config, "api_key", "").strip()
                ):
                    return await self._process_with_llm_direct(user_message)
                else:
                    return "No agent, flow, or LLM configuration available."
            else:
                return f"Flow mode ({self.flow_config.mode}) is not available. Please check your flow configuration."

        except Exception as e:
            print(f"Error processing with agent/flow: {e}")
            import traceback

            traceback.print_exc()
            return f"Error processing request: {str(e)}"

    async def _process_with_llm_direct(self, user_message: str) -> str:
        """ç›´æ¥ä½¿ç”¨LLM APIå¤„ç†æ¶ˆæ¯"""
        try:
            import json

            import requests

            # å®‰å…¨è·å–é…ç½®å±æ€§
            api_key = getattr(self.llm_config, "api_key", "")
            model = getattr(self.llm_config, "model", "gpt-3.5-turbo")
            base_url = getattr(
                self.llm_config, "base_url", "https://openrouter.ai/api/v1"
            )
            max_tokens = getattr(self.llm_config, "max_tokens", 4000)
            temperature = getattr(self.llm_config, "temperature", 0.7)

            if not api_key:
                return "LLM APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•å¤„ç†è¯·æ±‚ã€‚"

            # å¹¿æ’­æ€è€ƒè¿‡ç¨‹
            await self._broadcast_stream_message(
                "think", {"content": f"æ­£åœ¨ä½¿ç”¨ {model} å¤„ç†æ‚¨çš„è¯·æ±‚..."}, 1, 3
            )

            # å‡†å¤‡APIè¯·æ±‚
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}",
            }

            data = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "You are a helpful AI assistant. Please provide clear and accurate responses.",
                    },
                    {"role": "user", "content": user_message},
                ],
                "max_tokens": max_tokens,
                "temperature": temperature,
            }

            # å¹¿æ’­åŠ¨ä½œ
            await self._broadcast_stream_message(
                "action",
                {
                    "tool_name": "llm_api",
                    "args": {"model": model, "message": user_message[:50] + "..."},
                },
                2,
                3,
            )

            # å‘é€APIè¯·æ±‚
            response = requests.post(
                f"{base_url}/chat/completions", headers=headers, json=data, timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]

                # å¹¿æ’­è§‚å¯Ÿç»“æœ
                await self._broadcast_stream_message(
                    "observe",
                    {
                        "tool_name": "llm_api",
                        "result": f"æ”¶åˆ°å›å¤: {content[:100]}...",
                        "success": True,
                    },
                    3,
                    3,
                )

                return content
            else:
                error_msg = f"LLM API Error: {response.status_code} - {response.text}"
                print(error_msg)
                return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{error_msg}"

        except Exception as e:
            print(f"Error in direct LLM processing: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"

    async def _update_status(self, status: str, step: int, action: str):
        """æ›´æ–°AgentçŠ¶æ€"""
        self.status.status = status
        self.status.current_step = step
        self.status.last_action = action

        # å¹¿æ’­çŠ¶æ€æ›´æ–°
        await manager.broadcast_json(
            {
                "type": "status_update",
                "data": self.status.dict(),
                "timestamp": datetime.now().isoformat(),
            }
        )

    async def _broadcast_user_message(self, message: ChatMessage):
        """å¹¿æ’­ç”¨æˆ·æ¶ˆæ¯"""
        await manager.broadcast_json(
            {
                "type": "user_message",
                "data": {
                    "message": message.message,
                    "timestamp": message.timestamp or datetime.now().isoformat(),
                },
            }
        )

    async def _broadcast_agent_response(self, response: str):
        """å¹¿æ’­Agentå“åº”"""
        await manager.broadcast_json(
            {
                "type": "agent_response",
                "data": {"response": response, "timestamp": datetime.now().isoformat()},
            }
        )

    def get_status(self) -> AgentStatus:
        """è·å–å½“å‰çŠ¶æ€"""
        return self.status

    def get_llm_config_info(self) -> Dict[str, Any]:
        """è·å–LLMé…ç½®ä¿¡æ¯ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
        if not self.llm_config:
            return {
                "available": False,
                "source": "none",
                "message": "No LLM configuration loaded",
            }

        try:
            config_info = {
                "available": True,
                "model": getattr(self.llm_config, "model", "unknown"),
                "api_type": getattr(self.llm_config, "api_type", "unknown"),
                "base_url": getattr(self.llm_config, "base_url", "unknown"),
                "max_tokens": getattr(self.llm_config, "max_tokens", "unknown"),
                "temperature": getattr(self.llm_config, "temperature", "unknown"),
                "api_key_configured": bool(
                    getattr(self.llm_config, "api_key", "").strip()
                ),
                "source": (
                    "app_config"
                    if hasattr(self.llm_config, "model")
                    else "backend_config"
                ),
            }

            # éšè—API keyï¼Œåªæ˜¾ç¤ºæ˜¯å¦é…ç½®äº†
            if hasattr(self.llm_config, "api_key"):
                api_key = getattr(self.llm_config, "api_key", "")
                if api_key.strip():
                    config_info["api_key_preview"] = (
                        api_key[:8] + "..." if len(api_key) > 8 else "***"
                    )
                else:
                    config_info["api_key_preview"] = "(not configured)"

            return config_info

        except Exception as e:
            return {"available": False, "source": "error", "error": str(e)}

    async def _broadcast_stream_message(
        self,
        message_type: str,
        data: Dict[str, Any],
        step: int,
        total_steps: Optional[int] = None,
    ):
        """å¹¿æ’­æµå¼æ¶ˆæ¯"""
        stream_message = AgentStreamMessage(
            message_type=message_type,
            data=data,
            step=step,
            total_steps=total_steps or self.status.max_steps,
            timestamp=datetime.now().isoformat(),
        )

        # è°ƒè¯•è¾“å‡º
        print(f"ğŸ”„ Broadcasting stream message: {message_type} - Step {step}")
        print(f"   Data: {data}")
        print(f"   Active connections: {manager.get_connection_count()}")

        broadcast_data = {
            "type": "agent_stream",
            "data": stream_message.dict(),
            "timestamp": datetime.now().isoformat(),
        }

        print(f"   Broadcast data: {broadcast_data}")

        if manager.get_connection_count() == 0:
            print("âš ï¸ No active WebSocket connections to broadcast to!")
        else:
            await manager.broadcast_json(broadcast_data)
            print(
                f"âœ… Message broadcasted to {manager.get_connection_count()} connections"
            )

    async def configure_flow(self, config: FlowConfiguration) -> FlowConfigResponse:
        """é…ç½®flowå’Œagent"""
        try:
            print(f"ğŸ”§ Configuring flow: {config.mode}")
            print(f"   Primary agent: {config.primaryAgent}")
            print(f"   Selected agents: {config.selectedAgents}")
            print(f"   Parameters: {config.parameters}")

            # ä¿å­˜é…ç½®
            self.flow_config = config

            # æ¸…ç†ç°æœ‰çš„agentå’Œflow
            await self.cleanup()

            # æ ¹æ®é…ç½®åˆ›å»ºæ–°çš„agentæˆ–flow
            if config.mode == "single_agent":
                await self._initialize_single_agent(config.primaryAgent)
            else:
                await self._initialize_flow(config)

            # æ£€æŸ¥åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
            if config.mode == "single_agent" and not self.current_agent:
                raise Exception(
                    f"Failed to initialize single agent: {config.primaryAgent}"
                )
            elif config.mode != "single_agent" and not self.current_flow:
                raise Exception(f"Failed to initialize flow: {config.mode}")

            # è¿”å›æˆåŠŸå“åº”
            return FlowConfigResponse(
                success=True,
                message=f"Successfully configured {config.mode} mode",
                applied_config=config,
                available_agents=self.get_available_agents(),
            )

        except Exception as e:
            print(f"âŒ Error configuring flow: {e}")
            import traceback

            traceback.print_exc()

            return FlowConfigResponse(
                success=False,
                message=f"Failed to configure flow: {str(e)}",
                applied_config=config,
                available_agents=self.get_available_agents(),
            )

    async def _initialize_single_agent(self, agent_type: str):
        """åˆå§‹åŒ–å•ä¸ªAgent"""
        try:
            if agent_type == "manus":
                # ä½¿ç”¨é»˜è®¤çš„Manus agent
                from app.agent.manus import Manus

                self.current_agent = await Manus.create()
            else:
                # åˆ›å»ºç‰¹å®šç±»å‹çš„agent
                agent_class = self._get_agent_class(agent_type)
                if agent_class:
                    self.current_agent = await agent_class.create()
                else:
                    raise ValueError(f"Unknown agent type: {agent_type}")

            self.current_flow = None
            self.is_demo_mode = False
            print(f"âœ… Initialized single agent: {agent_type}")

        except Exception as e:
            print(
                f"âš ï¸ Failed to initialize agent {agent_type}, falling back to demo mode: {e}"
            )
            self.current_agent = None
            self.is_demo_mode = True

    async def _initialize_flow(self, config: FlowConfiguration):
        """åˆå§‹åŒ–Flow"""
        try:
            print(f"ğŸ”§ Initializing Flow: {config.mode}")
            print(f"   Primary agent: {config.primaryAgent}")
            print(f"   Selected agents: {config.selectedAgents}")
            print(f"   Parameters: {config.parameters}")

            from app.flow.flow_factory import FlowFactory, FlowType

            # åˆ›å»ºagentså­—å…¸
            agents = {}

            # æ·»åŠ ä¸»è¦agent
            if config.primaryAgent:
                print(f"ğŸ”§ Creating primary agent: {config.primaryAgent}")
                primary_agent_class = self._get_agent_class(config.primaryAgent)
                if primary_agent_class:
                    try:
                        # ä½¿ç”¨asyncio.wait_foræ·»åŠ 60ç§’è¶…æ—¶
                        agents[config.primaryAgent] = await asyncio.wait_for(
                            primary_agent_class.create(), timeout=60.0
                        )
                        print(f"âœ… Primary agent created: {config.primaryAgent}")
                    except asyncio.TimeoutError:
                        print(
                            f"â° Primary agent creation timeout: {config.primaryAgent}"
                        )
                        print(
                            f"âš ï¸ Skipping primary agent {config.primaryAgent} due to timeout"
                        )
                    except Exception as e:
                        print(
                            f"âŒ Failed to create primary agent {config.primaryAgent}: {e}"
                        )
                        print(
                            f"âš ï¸ Skipping primary agent {config.primaryAgent} due to error: {e}"
                        )
                else:
                    print(f"âš ï¸ Primary agent class not found: {config.primaryAgent}")
            else:
                print("âš ï¸ No primary agent specified")

            # æ·»åŠ é€‰ä¸­çš„agents
            for agent_type in config.selectedAgents:
                if agent_type not in agents:  # é¿å…é‡å¤
                    print(f"ğŸ”§ Creating selected agent: {agent_type}")
                    agent_class = self._get_agent_class(agent_type)
                    if agent_class:
                        try:
                            # ä½¿ç”¨asyncio.wait_foræ·»åŠ 60ç§’è¶…æ—¶
                            agents[agent_type] = await asyncio.wait_for(
                                agent_class.create(), timeout=60.0
                            )
                            print(f"âœ… Selected agent created: {agent_type}")
                        except asyncio.TimeoutError:
                            print(f"â° Selected agent creation timeout: {agent_type}")
                            # ä¸è¦å› ä¸ºä¸€ä¸ªAgentå¤±è´¥å°±ç»ˆæ­¢æ•´ä¸ªæµç¨‹
                            print(
                                f"âš ï¸ Skipping {agent_type} due to timeout, continuing with other agents..."
                            )
                            continue
                        except Exception as e:
                            print(
                                f"âŒ Failed to create selected agent {agent_type}: {e}"
                            )
                            # ä¸è¦å› ä¸ºä¸€ä¸ªAgentå¤±è´¥å°±ç»ˆæ­¢æ•´ä¸ªæµç¨‹
                            print(
                                f"âš ï¸ Skipping {agent_type} due to error, continuing with other agents..."
                            )
                            continue
                    else:
                        print(f"âš ï¸ Agent class not found for {agent_type}, skipping...")

            print(f"âœ… Total agents successfully created: {len(agents)}")

            # å¦‚æœæ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•Agentï¼Œä½¿ç”¨é»˜è®¤çš„Manus agent
            if not agents:
                print(
                    "âš ï¸ No agents were created successfully, falling back to default Manus agent"
                )
                try:
                    from app.agent.manus import Manus

                    agents["manus"] = await Manus.create()
                    print("âœ… Fallback Manus agent created successfully")
                except Exception as e:
                    print(f"âŒ Even fallback Manus agent failed: {e}")
                    raise Exception("Failed to create any agents for the flow")

            # æ˜ å°„flowç±»å‹
            flow_type_map = {
                "planning": FlowType.PLANNING,
                "game_data_analysis": FlowType.GAME_DATA_ANALYSIS,
                "data_analysis_flow": FlowType.DATA_ANALYSIS_FLOW,
            }

            flow_type = flow_type_map.get(config.mode)
            if not flow_type:
                raise ValueError(f"Unknown flow type: {config.mode}")

            print(f"ğŸ”§ Creating flow of type: {flow_type}")

            # åˆ›å»ºflow
            flow_kwargs = {}
            if config.parameters:
                flow_kwargs.update(config.parameters)
                print(f"ğŸ”§ Flow kwargs: {flow_kwargs}")

            self.current_flow = FlowFactory.create_flow(
                flow_type, agents, **flow_kwargs
            )
            self.current_agent = None  # Flowæ¨¡å¼ä¸‹ä¸ä½¿ç”¨å•ä¸ªagent
            self.is_demo_mode = False
            print(f"âœ… Initialized flow: {config.mode} with {len(agents)} agents")
            print(f"   Flow instance: {type(self.current_flow).__name__}")

        except Exception as e:
            print(f"âŒ Failed to initialize flow {config.mode}: {e}")
            import traceback

            traceback.print_exc()

            self.current_flow = None
            self.current_agent = None
            self.is_demo_mode = True
            raise e  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…çŸ¥é“å¤±è´¥äº†

    def _get_agent_class(self, agent_type: str):
        """è·å–Agentç±»"""
        try:
            print(f"ğŸ” Getting agent class for: {agent_type}")

            agent_class_map = {
                "manus": "app.agent.manus.Manus",
                "Manus": "app.agent.manus.Manus",  # æ·»åŠ å¤§å†™ç‰ˆæœ¬
                "DataAnalysisExpert": "app.agent.DataAnalysisExpert.DataAnalysisExpert",
                "ExcelCleanAgent": "app.agent.excel_data_cleaner.ExcelCleanAgent",
                "GameDataAnalysisAgent": "app.agent.game_data_analysis.GameDataAnalysisAgent",
                "SWEAgent": "app.agent.swe.SWEAgent",
                "BrowserAgent": "app.agent.browser.BrowserAgent",
                "AnswerQuestionAgent": "app.agent.AnswerQuestionAgent.AnalysisResultQnAAgent",  # ä¿®æ­£ä¸ºæ­£ç¡®çš„ç±»å
                "AnalysisResultQnAAgent": "app.agent.AnswerQuestionAgent.AnalysisResultQnAAgent",  # ä¿®æ­£ä¸ºæ­£ç¡®çš„ç±»å
                "data_analysis": "app.agent.data_analysis.DataAnalysis",
                "DataAnalysis": "app.agent.data_analysis.DataAnalysis",  # æ·»åŠ å¤§å†™ç‰ˆæœ¬
                # æ–°å¢Game Data Analysisç›¸å…³Agent - æ›´æ–°ä¸ºæ­£ç¡®çš„è·¯å¾„å’Œç±»å
                "MultiDataAnalysisCoordinator": "app.agent.lead_agent.MultiDataAnalysisCoordinator",  # ä¿®æ­£ä¸ºæ­£ç¡®çš„è·¯å¾„
                "KeyMetricAnalysisAgent": "app.agent.key_metric_analysis_agent.KeyMetricAnalysisAgent",
            }

            class_path = agent_class_map.get(agent_type)
            if not class_path:
                print(f"âŒ Unknown agent type: {agent_type}")
                return None

            print(f"ğŸ” Importing class from: {class_path}")
            module_path, class_name = class_path.rsplit(".", 1)

            try:
                module = __import__(module_path, fromlist=[class_name])
                agent_class = getattr(module, class_name)

                # æ£€æŸ¥ç±»æ˜¯å¦æœ‰createæ–¹æ³•
                if hasattr(agent_class, "create"):
                    print(f"âœ… Agent class {class_name} has create() method")
                    return agent_class
                elif hasattr(agent_class, "__init__"):
                    print(
                        f"âš ï¸ Agent class {class_name} has __init__ but no create() method"
                    )
                    # åˆ›å»ºä¸€ä¸ªåŒ…è£…å™¨æ¥å¤„ç†æ²¡æœ‰createæ–¹æ³•çš„ç±»
                    return self._create_agent_wrapper(agent_class, class_name)
                else:
                    print(
                        f"âŒ Agent class {class_name} has neither create() nor __init__ method"
                    )
                    return None

            except ImportError as e:
                print(f"âŒ Failed to import {class_path}: {e}")
                return None
            except AttributeError as e:
                print(
                    f"âŒ Failed to get class {class_name} from module {module_path}: {e}"
                )
                return None

        except Exception as e:
            print(f"âŒ Error getting agent class {agent_type}: {e}")
            import traceback

            traceback.print_exc()
            return None

    def _create_agent_wrapper(self, agent_class, class_name):
        """ä¸ºæ²¡æœ‰createæ–¹æ³•çš„Agentç±»åˆ›å»ºåŒ…è£…å™¨"""

        class AgentWrapper:
            def __init__(self, original_class):
                self.original_class = original_class

            async def create(self):
                """å¼‚æ­¥åˆ›å»ºAgentå®ä¾‹"""
                try:
                    print(f"ğŸ”§ Creating {class_name} instance using __init__")

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ToolCallAgentæˆ–å…¶å­ç±»
                    if hasattr(self.original_class, "__mro__"):
                        class_hierarchy = [
                            cls.__name__ for cls in self.original_class.__mro__
                        ]
                        print(f"  ğŸ“‹ Class hierarchy: {class_hierarchy}")

                        # å¦‚æœæ˜¯ToolCallAgentçš„å­ç±»ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                        if (
                            "ToolCallAgent" in class_hierarchy
                            or "ReActAgent" in class_hierarchy
                        ):
                            print(
                                f"  ğŸ”§ {class_name} is a ToolCallAgent, initializing with default config"
                            )
                            # ToolCallAgentç±»é€šå¸¸éœ€è¦é¢å¤–çš„åˆå§‹åŒ–
                            instance = self.original_class()

                            # å°è¯•åˆå§‹åŒ–MCPæœåŠ¡å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            if hasattr(instance, "initialize_mcp_servers"):
                                try:
                                    await instance.initialize_mcp_servers()
                                    print(
                                        f"  âœ… MCP servers initialized for {class_name}"
                                    )
                                except Exception as e:
                                    print(
                                        f"  âš ï¸ Failed to initialize MCP servers for {class_name}: {e}"
                                    )

                            # è®¾ç½®åˆå§‹åŒ–æ ‡å¿—
                            if hasattr(instance, "_initialized"):
                                instance._initialized = True

                            print(f"  âœ… Successfully created {class_name} instance")
                            return instance
                        else:
                            # æ™®é€šç±»ï¼Œç›´æ¥å®ä¾‹åŒ–
                            instance = self.original_class()
                            print(f"  âœ… Successfully created {class_name} instance")
                            return instance
                    else:
                        # ç›´æ¥å®ä¾‹åŒ–
                        instance = self.original_class()
                        print(f"  âœ… Successfully created {class_name} instance")
                        return instance

                except Exception as e:
                    print(f"  âŒ Failed to create {class_name} instance: {e}")
                    import traceback

                    traceback.print_exc()
                    raise e

        return AgentWrapper(agent_class)

    def get_available_agents(self) -> List[str]:
        """è·å–å¯ç”¨çš„Agentåˆ—è¡¨"""
        return [
            "Manus",
            "DataAnalysisExpert",
            "ExcelCleanAgent",
            "GameDataAnalysisAgent",
            "SWEAgent",
            "BrowserAgent",
            "AnalysisResultQnAAgent",
            "DataAnalysis",
            # Game Data Analysis ä¸“ç”¨Agent
            "MultiDataAnalysisCoordinator",
            "KeyMetricAnalysisAgent",
            "AnalysisResultQnAAgent",
        ]

    def get_current_flow_config(self) -> FlowConfiguration:
        """è·å–å½“å‰flowé…ç½®"""
        return self.flow_config

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # æ¸…ç†agent
        if self.current_agent and hasattr(self.current_agent, "cleanup"):
            try:
                await self.current_agent.cleanup()
            except Exception as e:
                print(f"Error cleaning up agent: {e}")

        # æ¸…ç†flow
        if self.current_flow and hasattr(self.current_flow, "cleanup"):
            try:
                await self.current_flow.cleanup()
            except Exception as e:
                print(f"Error cleaning up flow: {e}")

        self.current_agent = None
        self.current_flow = None


class StreamingFlowWrapper:
    """Flowæµå¼è¾“å‡ºåŒ…è£…å™¨ - é€šè¿‡æ‹¦æˆªæ—¥å¿—å®ç°æµå¼è¾“å‡º"""

    def __init__(self, flow, broadcast_callback):
        self.flow = flow
        self.broadcast = broadcast_callback

    async def run(self, request: Optional[str] = None) -> str:
        """æ‰§è¡ŒFlowå¹¶é€šè¿‡æ—¥å¿—æ‹¦æˆªå®ç°æµå¼è¾“å‡º"""
        try:
            # å¹¿æ’­å¼€å§‹æ¶ˆæ¯
            await self.broadcast(
                "start",
                {
                    "description": "Data Analysis Flowå¼€å§‹æ‰§è¡Œä»»åŠ¡...",
                    "request": request or "ç»§ç»­å¯¹è¯",
                },
                0,
                5,  # Flowçš„ä¼°è®¡æ­¥éª¤æ•°
            )

            # ä½¿ç”¨æ—¥å¿—æ‹¦æˆªå™¨æ•è·Flowå†…éƒ¨çš„æ‰€æœ‰æ—¥å¿—
            with LoggingInterceptor(self.broadcast):
                print(f"ğŸ”§ Executing flow with request: {request}")
                print(f"   Flow type: {type(self.flow).__name__}")
                print(
                    f"   Flow agents: {list(self.flow.agents.keys()) if hasattr(self.flow, 'agents') else 'No agents'}"
                )

                # æ‰§è¡ŒFlow - ç°åœ¨æ‰€æœ‰å†…éƒ¨æ—¥å¿—éƒ½ä¼šè¢«æ‹¦æˆªå¹¶è½¬æ¢ä¸ºæµå¼æ¶ˆæ¯
                result = await self.flow.execute(request)
                print(f"âœ… Flow execution completed: {result}")

            # å¹¿æ’­å®Œæˆæ¶ˆæ¯
            await self.broadcast(
                "complete",
                {
                    "result": result or "Flow execution completed",
                    "description": "Data Analysis Flowæ‰§è¡Œå®Œæˆ",
                },
                5,
                5,
            )

            return result or "Flow execution completed successfully"

        except Exception as e:
            print(f"âŒ Flow execution error: {e}")
            import traceback

            traceback.print_exc()

            await self.broadcast(
                "error",
                {"error": str(e), "description": "Flowæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"},
                0,
                5,
            )
            return f"Flow execution failed: {str(e)}"


class StreamingAgentWrapper:
    """Agentæµå¼è¾“å‡ºåŒ…è£…å™¨ - é€šè¿‡æ—¥å¿—æ‹¦æˆªå’ŒåŸæœ‰é€»è¾‘ç»“åˆå®ç°æµå¼è¾“å‡º"""

    def __init__(self, agent, broadcast_callback):
        self.agent = agent
        self.broadcast = broadcast_callback

    async def run(self, request: Optional[str] = None) -> str:
        """é‡å†™runæ–¹æ³•ï¼Œç»“åˆæ—¥å¿—æ‹¦æˆªå®ç°è¯¦ç»†çš„æµå¼è¾“å‡º"""
        from app.sandbox.client import SANDBOX_CLIENT
        from app.schema import AgentState

        # æ£€æŸ¥çŠ¶æ€
        if self.agent.state != AgentState.IDLE:
            raise RuntimeError(f"Cannot run agent from state: {self.agent.state}")

        # æ·»åŠ ç”¨æˆ·è¯·æ±‚åˆ°å†…å­˜
        if request:
            self.agent.update_memory("user", request)

        # å¹¿æ’­å¼€å§‹æ¶ˆæ¯
        await self.broadcast(
            "start",
            {
                "description": "AI Agentå¼€å§‹æ‰§è¡Œä»»åŠ¡...",
                "request": request or "ç»§ç»­å¯¹è¯",
            },
            0,
            self.agent.max_steps,
        )

        results = []

        # ä½¿ç”¨æ—¥å¿—æ‹¦æˆªå™¨ + åŸæœ‰é€»è¾‘ç›¸ç»“åˆ
        with LoggingInterceptor(self.broadcast):
            # ä½¿ç”¨çŠ¶æ€ä¸Šä¸‹æ–‡
            async with self.agent.state_context(AgentState.RUNNING):
                while (
                    self.agent.current_step < self.agent.max_steps
                    and self.agent.state != AgentState.FINISHED
                ):
                    self.agent.current_step += 1

                    # å¹¿æ’­æ­¥éª¤å¼€å§‹
                    await self.broadcast(
                        "step_start",
                        {
                            "step": self.agent.current_step,
                            "description": f"æ‰§è¡Œæ­¥éª¤ {self.agent.current_step}/{self.agent.max_steps}",
                        },
                        self.agent.current_step,
                        self.agent.max_steps,
                    )

                    try:
                        # æ‰§è¡Œæ€è€ƒé˜¶æ®µ - æ—¥å¿—ä¼šè¢«è‡ªåŠ¨æ‹¦æˆª
                        await self.broadcast(
                            "think_start",
                            {"content": "Agentæ­£åœ¨åˆ†æå½“å‰æƒ…å†µå¹¶åˆ¶å®šä¸‹ä¸€æ­¥è®¡åˆ’..."},
                            self.agent.current_step,
                            self.agent.max_steps,
                        )

                        should_act = await self.agent.think()

                        # è·å–æ€è€ƒå†…å®¹
                        think_content = ""
                        if self.agent.messages and len(self.agent.messages) > 0:
                            last_message = self.agent.messages[-1]
                            if last_message.content:
                                think_content = last_message.content[:500]  # é™åˆ¶é•¿åº¦

                        await self.broadcast(
                            "think",
                            {
                                "content": think_content,
                                "reasoning": "Agentå·²å®Œæˆåˆ†æï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨",
                                "will_act": should_act,
                            },
                            self.agent.current_step,
                            self.agent.max_steps,
                        )

                        if not should_act:
                            step_result = "æ€è€ƒå®Œæˆ - æ— éœ€è¿›ä¸€æ­¥è¡ŒåŠ¨"
                        else:
                            # æ‰§è¡Œè¡ŒåŠ¨é˜¶æ®µ - å·¥å…·è°ƒç”¨æ—¥å¿—ä¼šè¢«è‡ªåŠ¨æ‹¦æˆª
                            # å¹¿æ’­å³å°†æ‰§è¡Œçš„å·¥å…·
                            if (
                                hasattr(self.agent, "tool_calls")
                                and self.agent.tool_calls
                            ):
                                for tool_call in self.agent.tool_calls:
                                    await self.broadcast(
                                        "act",
                                        {
                                            "tool_name": tool_call.function.name,
                                            "tool_args": (
                                                tool_call.function.arguments[:200]
                                                if tool_call.function.arguments
                                                else ""
                                            ),
                                            "description": f"æ‰§è¡Œå·¥å…·: {tool_call.function.name}",
                                        },
                                        self.agent.current_step,
                                        self.agent.max_steps,
                                    )

                            # æ‰§è¡ŒåŠ¨ä½œ - Agentå†…éƒ¨çš„æ‰€æœ‰æ—¥å¿—éƒ½ä¼šè¢«æ‹¦æˆª
                            step_result = await self.agent.act()

                            # å¹¿æ’­æ‰§è¡Œç»“æœ
                            if (
                                hasattr(self.agent, "tool_calls")
                                and self.agent.tool_calls
                            ):
                                for tool_call in self.agent.tool_calls:
                                    await self.broadcast(
                                        "observe",
                                        {
                                            "tool_name": tool_call.function.name,
                                            "result": (
                                                step_result[:300]
                                                if step_result
                                                else "æ‰§è¡Œå®Œæˆ"
                                            ),
                                            "success": True,
                                        },
                                        self.agent.current_step,
                                        self.agent.max_steps,
                                    )

                        # æ£€æŸ¥æ˜¯å¦å¡ä½
                        if self.agent.is_stuck():
                            self.agent.handle_stuck_state()
                            await self.broadcast(
                                "observe",
                                {
                                    "tool_name": "system",
                                    "result": "æ£€æµ‹åˆ°é‡å¤å“åº”ï¼Œæ­£åœ¨è°ƒæ•´ç­–ç•¥...",
                                    "success": True,
                                },
                                self.agent.current_step,
                                self.agent.max_steps,
                            )

                        results.append(f"æ­¥éª¤ {self.agent.current_step}: {step_result}")

                        # å¹¿æ’­æ­¥éª¤å®Œæˆ
                        await self.broadcast(
                            "step_complete",
                            {
                                "step": self.agent.current_step,
                                "result": (
                                    step_result[:200] if step_result else "æ­¥éª¤å®Œæˆ"
                                ),
                                "description": f"æ­¥éª¤ {self.agent.current_step} æ‰§è¡Œå®Œæˆ",
                            },
                            self.agent.current_step,
                            self.agent.max_steps,
                        )

                        # å¦‚æœä»»åŠ¡å®Œæˆï¼Œè·³å‡ºå¾ªç¯
                        if self.agent.state == AgentState.FINISHED:
                            break

                    except Exception as e:
                        error_msg = f"æ­¥éª¤ {self.agent.current_step} æ‰§è¡Œå¤±è´¥: {str(e)}"
                        results.append(error_msg)

                        # å¹¿æ’­é”™è¯¯
                        await self.broadcast(
                            "error",
                            {
                                "error": str(e),
                                "step": self.agent.current_step,
                                "description": error_msg,
                            },
                            self.agent.current_step,
                            self.agent.max_steps,
                        )
                        break

                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ­¥æ•°
                if self.agent.current_step >= self.agent.max_steps:
                    self.agent.current_step = 0
                    self.agent.state = AgentState.IDLE
                    results.append(f"ä»»åŠ¡ç»ˆæ­¢ï¼šè¾¾åˆ°æœ€å¤§æ­¥æ•° ({self.agent.max_steps})")

        # æ¸…ç†æ²™ç®±
        await SANDBOX_CLIENT.cleanup()

        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        final_result = "\n".join(results) if results else "æœªæ‰§è¡Œä»»ä½•æ­¥éª¤"

        # å¹¿æ’­å®Œæˆæ¶ˆæ¯
        await self.broadcast(
            "complete",
            {
                "result": final_result,
                "total_steps": self.agent.current_step,
                "description": "ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            },
            self.agent.current_step,
            self.agent.max_steps,
        )

        return final_result


# =============================================================================
# æ–¹æ¡ˆ2: ç®€åŒ–ç‰ˆæ—¥å¿—æ‹¦æˆª + è£…é¥°å™¨æ¨¡å¼
# =============================================================================


def create_streaming_wrapper(original_method, broadcast_callback, method_name):
    """åˆ›å»ºæµå¼è¾“å‡ºè£…é¥°å™¨"""

    @wraps(original_method)
    async def wrapper(*args, **kwargs):
        try:
            # å¹¿æ’­æ–¹æ³•å¼€å§‹
            await broadcast_callback(
                f"{method_name}_start",
                {
                    "method": method_name,
                    "description": f"å¼€å§‹æ‰§è¡Œ {method_name}...",
                    "args_info": str(args[1:])[:100] if len(args) > 1 else "",
                },
                0,
                5,
            )

            # æ‰§è¡ŒåŸå§‹æ–¹æ³•
            result = await original_method(*args, **kwargs)

            # å¹¿æ’­æ–¹æ³•å®Œæˆ
            await broadcast_callback(
                f"{method_name}_complete",
                {
                    "method": method_name,
                    "description": f"{method_name} æ‰§è¡Œå®Œæˆ",
                    "result": str(result)[:200] if result else "Method completed",
                },
                1,
                5,
            )

            return result

        except Exception as e:
            # å¹¿æ’­é”™è¯¯
            await broadcast_callback(
                "error",
                {
                    "method": method_name,
                    "error": str(e),
                    "description": f"{method_name} æ‰§è¡Œå¤±è´¥",
                },
                0,
                5,
            )
            raise

    return wrapper


class SimpleMethodInterceptor:
    """ç®€åŒ–ç‰ˆæ–¹æ³•æ‹¦æˆªå™¨ - ä½¿ç”¨è£…é¥°å™¨æ¨¡å¼"""

    def __init__(self, broadcast_callback):
        self.broadcast = broadcast_callback
        self.patched_objects = []

    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡æ—¶å®‰è£…è£…é¥°å™¨"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡æ—¶æ¸…ç†"""
        self.patched_objects.clear()

    def patch_flow_instance(self, flow_instance):
        """ä¸ºFlowå®ä¾‹æ·»åŠ æµå¼è¾“å‡ºè£…é¥°å™¨"""
        try:
            # ä¸´æ—¶ç¦ç”¨method patchingä»¥é¿å…Pydanticå†²çª
            # TODO: å®ç°æ›´å®‰å…¨çš„æ–¹æ³•åŒ…è£…æœºåˆ¶
            print(f"âš ï¸ Method patching disabled for flow: {type(flow_instance).__name__}")
            ## pass

            # è£…é¥°executeæ–¹æ³• - ä½¿ç”¨setattrç»•è¿‡Pydanticå­—æ®µéªŒè¯
            if hasattr(flow_instance, "execute"):
                original_execute = getattr(flow_instance, "execute")
                wrapped_execute = create_streaming_wrapper(
                    original_execute, self.broadcast, "flow_execute"
                )
                # ä½¿ç”¨setattrç›´æ¥è®¾ç½®åˆ°å¯¹è±¡çš„__dict__æ¥ç»•è¿‡PydanticéªŒè¯
                object.__setattr__(flow_instance, "execute", wrapped_execute)
                self.patched_objects.append(
                    (flow_instance, "execute", original_execute)
                )

            # è£…é¥°_execute_stepæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(flow_instance, "_execute_step"):
                original_step = getattr(flow_instance, "_execute_step")
                wrapped_step = create_streaming_wrapper(
                    original_step, self.broadcast, "execute_step"
                )
                object.__setattr__(flow_instance, "_execute_step", wrapped_step)
                self.patched_objects.append(
                    (flow_instance, "_execute_step", original_step)
                )

        except Exception as e:
            print(f"âš ï¸ Failed to patch flow instance: {e}")
            import traceback
            traceback.print_exc()

    def patch_agent_instance(self, agent_instance):
        """ä¸ºAgentå®ä¾‹æ·»åŠ æµå¼è¾“å‡ºè£…é¥°å™¨"""
        try:
            # è£…é¥°runæ–¹æ³•
            if hasattr(agent_instance, "run"):
                original_run = agent_instance.run
                agent_instance.run = create_streaming_wrapper(
                    original_run, self.broadcast, "agent_run"
                )
                self.patched_objects.append((agent_instance, "run", original_run))

        except Exception as e:
            print(f"âš ï¸ Failed to patch agent instance: {e}")


class HybridStreamingFlowWrapper:
    """æ··åˆå¼FlowåŒ…è£…å™¨ - ç»“åˆæ—¥å¿—æ‹¦æˆªå’Œæ–¹æ³•è£…é¥°"""

    def __init__(self, flow, broadcast_callback):
        self.flow = flow
        self.broadcast = broadcast_callback

    async def run(self, request: Optional[str] = None) -> str:
        """ä½¿ç”¨æ··åˆå¼æ–¹æ³•æ‰§è¡ŒFlow"""
        try:
            # å¹¿æ’­å¼€å§‹æ¶ˆæ¯
            await self.broadcast(
                "start",
                {
                    "description": "Hybrid Data Analysis Flowå¼€å§‹æ‰§è¡Œ...",
                    "request": request or "ç»§ç»­å¯¹è¯",
                    "flow_type": type(self.flow).__name__,
                },
                0,
                8,
            )

            # æ–¹æ³•1: ä½¿ç”¨æ—¥å¿—æ‹¦æˆªå™¨
            log_interceptor = LoggingInterceptor(self.broadcast)

            # æ–¹æ³•2: ä½¿ç”¨æ–¹æ³•è£…é¥°å™¨
            method_interceptor = SimpleMethodInterceptor(self.broadcast)

            with log_interceptor:
                with method_interceptor:
                    # ä¸ºå½“å‰Flowå®ä¾‹æ·»åŠ è£…é¥°å™¨
                    method_interceptor.patch_flow_instance(self.flow)

                    # å¦‚æœFlowæœ‰agentsï¼Œä¹Ÿä¸ºå®ƒä»¬æ·»åŠ è£…é¥°å™¨
                    if hasattr(self.flow, "agents") and self.flow.agents:
                        for agent_key, agent in self.flow.agents.items():
                            method_interceptor.patch_agent_instance(agent)

                    # æ‰§è¡ŒFlow - ç°åœ¨ä¼šæœ‰å¤šå±‚æ‹¦æˆª
                    print(f"ğŸ”§ Executing hybrid flow with request: {request}")
                    result = await self.flow.execute(request)
                    print(f"âœ… Hybrid flow execution completed: {result}")

            # å¹¿æ’­å®Œæˆæ¶ˆæ¯
            await self.broadcast(
                "complete",
                {
                    "result": result or "Hybrid Flow execution completed",
                    "description": "Hybrid Data Analysis Flowæ‰§è¡Œå®Œæˆ",
                    "flow_type": type(self.flow).__name__,
                },
                8,
                8,
            )

            return result or "Hybrid Flow execution completed successfully"

        except Exception as e:
            print(f"âŒ Hybrid flow execution error: {e}")
            import traceback

            traceback.print_exc()

            await self.broadcast(
                "error",
                {"error": str(e), "description": "Hybrid Flowæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"},
                0,
                8,
            )
            return f"Hybrid Flow execution failed: {str(e)}"


# å…¨å±€AgentæœåŠ¡å®ä¾‹
agent_service = AgentService()
